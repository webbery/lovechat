{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\yuanwb\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.009 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pair('蕾', 'nr'), pair('姆', 'x'), pair('蕾', 'nr'), pair('姆', 'x'), pair('这个', 'r'), pair('人', 'n'), pair('是不是', 'l'), pair('傻', 'a')]\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import re\n",
    "import jieba.analyse\n",
    "import jieba.posseg\n",
    "\n",
    "def cut_sentence(sentence):\n",
    "    cleaned_data = ''.join(re.findall(r'[\\u4e00-\\u9fa5]', sentence))\n",
    "    return jieba.posseg.lcut(cleaned_data)\n",
    "\n",
    "word=\"盗墓不是请客吃饭，不是做文章，不是绘画绣花，不能那样雅致，那样从容不迫，文质彬彬，那样温良恭俭让，盗墓是一门技术，一门进行破坏的技术。古代贵族们建造坟墓的时候，一定是想方设法的防止被盗，故此无所不用其极，在墓中设置种种机关暗器，消息埋伏，有巨石、流沙、毒箭、毒虫、陷坑等等数不胜数。到了明代，受到西洋奇技淫巧的影响，一些大墓甚至用到了西洋的八宝转心机关，尤其是清代的帝陵，堪称集数千年防盗技术于一体的杰作，大军阀孙殿英想挖开东陵用里面的财宝充当军饷，起动大批军队，连挖带炸用了五六天才得手，其坚固程度可想而知。盗墓贼的课题就是千方百计的破解这些机关，进入墓中探宝。不过在现代，比起如何挖开古墓更困难的是寻找古墓，地面上有封土堆和石碑之类明显建筑的大墓早就被人发掘得差不多了，如果要找那些年深日深藏于地下，又没有任何地上标记的古墓，那就需要一定的技术和特殊工具了，铁钎、洛阳铲、竹钉，钻地龙，探阴爪，黑折子等工具都应运而生，还有一些高手不依赖工具，有的通过寻找古代文献中的线索寻找古墓，还有极少数的一些人掌握秘术，可以通过解读山川河流的脉象，用看风水的本领找墓穴，我就是属于最后这一类的，在我的盗墓生涯中踏遍了各地，其间经历了很多诡异离奇的事迹，若是一件件的表白出来，足以让观者惊心，闻者乍舌，毕竟那些龙形虎藏、揭天拔地、倒海翻江的举动，都非比寻常。\"\n",
    "sentence = \"蕾姆蕾姆,这个人是不是傻？\"\n",
    "wordlist = cut_sentence(sentence)\n",
    "print(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pair('团队', 'n'), pair('因', 'p'), pair('无法', 'n'), pair('登陆', 'v'), pair('暂时', 'd'), pair('无法', 'n'), pair('解决', 'v'), pair('无法', 'n'), pair('登陆', 'v'), pair('问题', 'n')]\n"
     ]
    }
   ],
   "source": [
    "wordlist = cut_sentence('VPN团队因无法登陆VPN暂时无法解决VPN无法登陆问题')\n",
    "print(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LookupTableImportV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MutexV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "import hanlp\n",
    "\n",
    "tokenizer = hanlp.load('PKU_NAME_MERGED_SIX_MONTHS_CONVSEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntaxnNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IP：简单从句\n",
    "NP：名词短语\n",
    "VP：动词短语\n",
    "PU：断句符，通常是句号、问号、感叹号等标点符号\n",
    "LCP：方位词短语\n",
    "PP：介词短语\n",
    "CP：由‘的’构成的表示修饰性关系的短语\n",
    "DNP：由‘的’构成的表示所属关系的短语\n",
    "ADVP：副词短语\n",
    "ADJP：形容词短语\n",
    "DP：限定词短语\n",
    "QP：量词短语\n",
    "NN：常用名词\n",
    "NR：固有名词\n",
    "NT：时间名词\n",
    "PN：代词\n",
    "VV：动词\n",
    "VC：是\n",
    "CC：表示连词\n",
    "VE：有\n",
    "VA：表语形容词\n",
    "AS：内容标记（如：了）\n",
    "VRD：动补复合词\n",
    "CD: 表示基数词\n",
    "DT: determiner 表示限定词\n",
    "EX: existential there 存在句\n",
    "FW: foreign word 外来词\n",
    "IN: preposition or conjunction, subordinating 介词或从属连词\n",
    "JJ: adjective or numeral, ordinal 形容词或序数词\n",
    "JJR: adjective, comparative 形容词比较级\n",
    "JJS: adjective, superlative 形容词最高级\n",
    "LS: list item marker 列表标识\n",
    "MD: modal auxiliary 情态助动词\n",
    "PDT: pre-determiner 前位限定词\n",
    "POS: genitive marker 所有格标记\n",
    "PRP: pronoun, personal 人称代词\n",
    "RB: adverb 副词\n",
    "RBR: adverb, comparative 副词比较级\n",
    "RBS: adverb, superlative 副词最高级\n",
    "RP: particle 小品词 \n",
    "SYM: symbol 符号\n",
    "TO:”to” as preposition or infinitive marker 作为介词或不定式标记 \n",
    "WDT: WH-determiner WH限定词\n",
    "WP: WH-pronoun WH代词\n",
    "WP$: WH-pronoun, possessive WH所有格代词\n",
    "WRB:Wh-adverb WH副词\n",
    "    \n",
    "关系表示\n",
    "abbrev: abbreviation modifier，缩写\n",
    "acomp: adjectival complement，形容词的补充；\n",
    "advcl : adverbial clause modifier，状语从句修饰词\n",
    "advmod: adverbial modifier状语\n",
    "agent: agent，代理，一般有by的时候会出现这个\n",
    "amod: adjectival modifier形容词\n",
    "appos: appositional modifier,同位词\n",
    "attr: attributive，属性\n",
    "aux: auxiliary，非主要动词和助词，如BE,HAVE SHOULD/COULD等到\n",
    "auxpass: passive auxiliary 被动词\n",
    "cc: coordination，并列关系，一般取第一个词\n",
    "ccomp: clausal complement从句补充\n",
    "complm: complementizer，引导从句的词好重聚中的主要动词\n",
    "conj : conjunct，连接两个并列的词。\n",
    "cop: copula。系动词（如be,seem,appear等），（命题主词与谓词间的）连系\n",
    "csubj : clausal subject，从主关系\n",
    "csubjpass: clausal passive subject 主从被动关系\n",
    "dep: dependent依赖关系\n",
    "det: determiner决定词，如冠词等\n",
    "dobj : direct object直接宾语\n",
    "expl: expletive，主要是抓取there\n",
    "infmod: infinitival modifier，动词不定式\n",
    "iobj : indirect object，非直接宾语，也就是所以的间接宾语；\n",
    "mark: marker，主要出现在有“that” or “whether”“because”, “when”,\n",
    "mwe: multi-word expression，多个词的表示\n",
    "neg: negation modifier否定词\n",
    "nn: noun compound modifier名词组合形式\n",
    "npadvmod: noun phrase as adverbial modifier名词作状语\n",
    "nsubj : nominal subject，名词主语\n",
    "nsubjpass: passive nominal subject，被动的名词主语\n",
    "num: numeric modifier，数值修饰\n",
    "number: element of compound number，组合数字\n",
    "parataxis: parataxis: parataxis，并列关系\n",
    "partmod: participial modifier动词形式的修饰\n",
    "pcomp: prepositional complement，介词补充\n",
    "pobj : object of a preposition，介词的宾语\n",
    "poss: possession modifier，所有形式，所有格，所属\n",
    "possessive: possessive modifier，这个表示所有者和那个’S的关系\n",
    "preconj : preconjunct，常常是出现在 “either”, “both”, “neither”的情况下\n",
    "predet: predeterminer，前缀决定，常常是表示所有\n",
    "prep: prepositional modifier\n",
    "prepc: prepositional clausal modifier\n",
    "prt: phrasal verb particle，动词短语\n",
    "punct: punctuation，这个很少见，但是保留下来了，结果当中不会出现这个\n",
    "purpcl : purpose clause modifier，目的从句\n",
    "quantmod: quantifier phrase modifier，数量短语\n",
    "rcmod: relative clause modifier相关关系\n",
    "ref : referent，指示物，指代\n",
    "rel : relative\n",
    "root: root，最重要的词，从它开始，根节点\n",
    "tmod: temporal modifier\n",
    "xcomp: open clausal complement\n",
    "xsubj : controlling subject 掌控者\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "中心语为谓词\n",
    "  subj — 主语\n",
    " nsubj — 名词性主语（nominal subject） （同步，建设）\n",
    "   top — 主题（topic） （是，建筑）\n",
    "npsubj — 被动型主语（nominal passive subject），专指由“被”引导的被动句中的主语，一般是谓词语义上的受事 （称作，镍）\n",
    " csubj — 从句主语（clausal subject），中文不存在\n",
    " xsubj — x主语，一般是一个主语下面含多个从句 （完善，有些）\n",
    "\n",
    " \n",
    "\n",
    "中心语为谓词或介词   \n",
    "   obj — 宾语\n",
    "  dobj — 直接宾语 （颁布，文件）\n",
    "  iobj — 间接宾语（indirect object），基本不存在\n",
    " range — 间接宾语为数量词，又称为与格 （成交，元）\n",
    "  pobj — 介词宾语 （根据，要求）\n",
    "  lobj — 时间介词 （来，近年）\n",
    "\n",
    " \n",
    "\n",
    "中心语为谓词\n",
    "  comp — 补语\n",
    " ccomp — 从句补语，一般由两个动词构成，中心语引导后一个动词所在的从句(IP) （出现，纳入）\n",
    " xcomp — x从句补语（xclausal complement），不存在   \n",
    " acomp — 形容词补语（adjectival complement）\n",
    " tcomp — 时间补语（temporal complement） （遇到，以前）\n",
    "lccomp — 位置补语（localizer complement） （占，以上）\n",
    "       — 结果补语（resultative complement）\n",
    "\n",
    " \n",
    "\n",
    "中心语为名词\n",
    "   mod — 修饰语（modifier）\n",
    "  pass — 被动修饰（passive）\n",
    "  tmod — 时间修饰（temporal modifier）\n",
    " rcmod — 关系从句修饰（relative clause modifier） （问题，遇到）\n",
    " numod — 数量修饰（numeric modifier） （规定，若干）\n",
    "ornmod — 序数修饰（numeric modifier）\n",
    "   clf — 类别修饰（classifier modifier） （文件，件）\n",
    "  nmod — 复合名词修饰（noun compound modifier） （浦东，上海）\n",
    "  amod — 形容词修饰（adjetive modifier） （情况，新）\n",
    "advmod — 副词修饰（adverbial modifier） （做到，基本）\n",
    "  vmod — 动词修饰（verb modifier，participle modifier）\n",
    "prnmod — 插入词修饰（parenthetical modifier）\n",
    "   neg — 不定修饰（negative modifier） (遇到，不)\n",
    "   det — 限定词修饰（determiner modifier） （活动，这些）\n",
    " possm — 所属标记（possessive marker），NP\n",
    "  poss — 所属修饰（possessive modifier），NP\n",
    "  dvpm — DVP标记（dvp marker），DVP （简单，的）\n",
    "dvpmod — DVP修饰（dvp modifier），DVP （采取，简单）\n",
    "  assm — 关联标记（associative marker），DNP （开发，的）\n",
    "assmod — 关联修饰（associative modifier），NP|QP （教训，特区）\n",
    "  prep — 介词修饰（prepositional modifier） NP|VP|IP（采取，对）\n",
    " clmod — 从句修饰（clause modifier） （因为，开始）\n",
    " plmod — 介词性地点修饰（prepositional localizer modifier） （在，上）\n",
    "   asp — 时态标词（aspect marker） （做到，了）\n",
    "partmod– 分词修饰（participial modifier） 不存在\n",
    "   etc — 等关系（etc） （办法，等）\n",
    "\n",
    " \n",
    "\n",
    "中心语为实词\n",
    "  conj — 联合(conjunct)\n",
    "   cop — 系动(copula) 双指助动词？？？？\n",
    "    cc — 连接(coordination)，指中心词与连词 （开发，与）\n",
    "\n",
    " \n",
    "\n",
    "其它\n",
    "  attr — 属性关系 （是，工程）\n",
    "cordmod– 并列联合动词（coordinated verb compound） （颁布，实行）\n",
    "  mmod — 情态动词（modal verb） （得到，能）\n",
    "    ba — 把字关系\n",
    "tclaus — 时间从句 （以后，积累）\n",
    "       — semantic dependent\n",
    "   cpm — 补语化成分（complementizer），一般指“的”引导的CP （振兴，的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 84\n",
      "['quantmod', 'acomp', 'aux', 'abbrev', 'xcomp', 'ref', 'clmod', 'attr', 'amod', 'possessive', 'dobj', 'tclaus', 'num', 'prep', 'advmod', 'punct', 'assm', 'comp', 'prepc', 'xsubj', 'auxpass', 'mark', 'preconj', 'det', 'rcomp', 'ornmod', 'infmod', 'iobj', 'lobj', 'tmod', 'asp', 'dvpmod', 'prnmod', 'plmod', 'cordmod', 'cpm', 'conj', 'pass', 'complm', 'nmod', 'prt', 'ccomp', 'expl', 'predet', 'rel', 'range', 'numod', 'csubj', 'pobj', 'advcl', 'pcomp', 'parataxis', 'cop', 'npadvmod', 'dep', 'cc', 'neg', 'agent', 'assmod', 'root', 'etc', 'mmod', 'vmod', 'mwe', 'appos', 'rcmod', 'number', 'mod', 'possm', 'purpcl', 'nsubjpass', 'subj', 'clf', 'ba', 'csubjpass', 'dvpm', 'poss', 'partmod', 'nsubj', 'top', 'npsubj', 'nn', 'obj', 'lccomp']\n"
     ]
    }
   ],
   "source": [
    "relations = [\n",
    "    'abbrev','acomp','advcl','advmod','agent','amod','appos','aux','auxpass','complm','conj','csubj','csubjpass','dep','expl','infmod','mark',\n",
    "    'mwe','nn','npadvmod','nsubj','nsubjpass','num','number','parataxis','partmod','pcomp','possessive','preconj','predet','prepc','prt',\n",
    "    'punct','purpcl','quantmod','rcmod','ref','rel','root','tmod',\n",
    "    'subj','nsubj','top','npsubj','csubj','xsubj',\n",
    "    'obj','dobj','iobj','range','pobj','lobj',\n",
    "    'comp','ccomp','xcomp','acomp','acomp','lccomp','rcomp',\n",
    "    'mod','pass','tmod','rcmod','numod','ornmod','clf','nmod','amod','advmod','vmod','prnmod','neg','det','possm','poss','dvpm','dvpmod',\n",
    "    'assm','assmod','prep','clmod','plmod','asp','partmod','etc',\n",
    "    'conj','cop','cc',\n",
    "    'attr','cordmod','mmod','ba','tclaus','cpm'\n",
    "]\n",
    "ids = list(set(relations))\n",
    "print(len(relations),len(ids))\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch as t\n",
    "import torch.optim as opt\n",
    "\n",
    "# 三个d维的embedding，分别为词嵌入、pos tag嵌入、关系嵌入\n",
    "dim = len(relations)\n",
    "\n",
    "NULL = '<NULL>'\n",
    "ROOT = '<ROOT>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PaddedBatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['蕾姆蕾姆', '，', '这个', '人', '是', '不', '是', '傻', '？']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('蕾姆蕾姆，这个人是不是傻？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tagger = hanlp.load(hanlp.pretrained.pos.CTB5_POS_RNN_FASTTEXT_ZH)\n",
    "tagger(['蜡烛', '两', '头', '烧'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)\n",
    "recognizer([list('蜡烛两头烧')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op HashTableV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op NotEqual in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op GreaterEqual in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op SelectV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ResourceGather in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Qr in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DiagPart in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sign in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Transpose in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ExpandDims in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Transpose in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Unpack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BiasAdd in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Split in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sigmoid in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Tanh in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Unpack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZerosLike in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Less in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Tile in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op SelectV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReverseV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReverseV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LeakyRelu in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Einsum in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Einsum in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Squeeze in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op IteratorGetNextSync in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op UniqueWithCounts in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomShuffle in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ExpandDims in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Abs in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ArgMin in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Transpose in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op GatherNd in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Any in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ExpandDims in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sum in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RealDiv in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op All in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op GatherV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Unique in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op GatherV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Where in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Squeeze in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op SplitV in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Unpack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Unpack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ArgMax in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ExpandDims in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op GatherV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op NotEqual in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sum in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'form': '呵',\n",
       "  'cpos': 'AD',\n",
       "  'pos': None,\n",
       "  'head': 8,\n",
       "  'deprel': 'dep',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 2,\n",
       "  'form': '，',\n",
       "  'cpos': 'PU',\n",
       "  'pos': None,\n",
       "  'head': 8,\n",
       "  'deprel': 'punct',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 3,\n",
       "  'form': '愚蠢',\n",
       "  'cpos': 'VA',\n",
       "  'pos': None,\n",
       "  'head': 5,\n",
       "  'deprel': 'rcmod',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 4,\n",
       "  'form': '的',\n",
       "  'cpos': 'DEC',\n",
       "  'pos': None,\n",
       "  'head': 3,\n",
       "  'deprel': 'cpm',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 5,\n",
       "  'form': '人类',\n",
       "  'cpos': 'NN',\n",
       "  'pos': None,\n",
       "  'head': 8,\n",
       "  'deprel': 'nsubj',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 6,\n",
       "  'form': '，',\n",
       "  'cpos': 'PU',\n",
       "  'pos': None,\n",
       "  'head': 8,\n",
       "  'deprel': 'punct',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 7,\n",
       "  'form': '你',\n",
       "  'cpos': 'PN',\n",
       "  'pos': None,\n",
       "  'head': 8,\n",
       "  'deprel': 'nsubj',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 8,\n",
       "  'form': '想',\n",
       "  'cpos': 'VV',\n",
       "  'pos': None,\n",
       "  'head': 0,\n",
       "  'deprel': 'root',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 9,\n",
       "  'form': '跟',\n",
       "  'cpos': 'P',\n",
       "  'pos': None,\n",
       "  'head': 11,\n",
       "  'deprel': 'prep',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 10,\n",
       "  'form': '我',\n",
       "  'cpos': 'PN',\n",
       "  'pos': None,\n",
       "  'head': 9,\n",
       "  'deprel': 'pobj',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 11,\n",
       "  'form': '说',\n",
       "  'cpos': 'VV',\n",
       "  'pos': None,\n",
       "  'head': 8,\n",
       "  'deprel': 'ccomp',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 12,\n",
       "  'form': '什么',\n",
       "  'cpos': 'PN',\n",
       "  'pos': None,\n",
       "  'head': 13,\n",
       "  'deprel': 'nsubj',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None},\n",
       " {'id': 13,\n",
       "  'form': '喵',\n",
       "  'cpos': 'VV',\n",
       "  'pos': None,\n",
       "  'head': 11,\n",
       "  'deprel': 'ccomp',\n",
       "  'lemma': None,\n",
       "  'feats': None,\n",
       "  'phead': None,\n",
       "  'pdeprel': None}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntactic_parser = hanlp.load(hanlp.pretrained.dep.CTB7_BIAFFINE_DEP_ZH)\n",
    "syntactic_parser([('呵', 'AD'), ('，', 'PU'), ('愚蠢', 'VA'), ('的', 'DEC'), ('人类', 'NN'), ('，', 'PU'), ('你', 'PN'), ('想', 'VV'), ('跟', 'P'), ('我', 'PN'), ('说', 'VV'), ('什么', 'PN'), ('喵', 'VV')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开放域聊天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>南京在哪里</td>\n",
       "      <td>在这里了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>咋死???红烧还是爆炒</td>\n",
       "      <td>哦了哦了哦了,咱聊点别的吧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>你个小骚货，哥哥的巴操你爽不爽？</td>\n",
       "      <td>不要这样说嘛！很不文明哦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>额麻麻怎么会有那玩意儿</td>\n",
       "      <td>无法理解您的话，获取帮助请发送 help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>孩纸,新年快乐</td>\n",
       "      <td>{r+}同乐同乐，大家一起乐~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          #Question                Answer\n",
       "0             南京在哪里                  在这里了\n",
       "1       咋死???红烧还是爆炒         哦了哦了哦了,咱聊点别的吧\n",
       "2  你个小骚货，哥哥的巴操你爽不爽？          不要这样说嘛！很不文明哦\n",
       "3       额麻麻怎么会有那玩意儿  无法理解您的话，获取帮助请发送 help\n",
       "4           孩纸,新年快乐       {r+}同乐同乐，大家一起乐~"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chat_data = pd.read_csv('./raw_chat_corpus/qingyun-11w/12万对话语料青云库.csv',sep='\\t')\n",
    "chat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语义向量提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>怎么更改花呗手机号码</td>\n",
       "      <td>我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>也开不了花呗，就这样了？完事了</td>\n",
       "      <td>真的嘛？就是花呗付款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>花呗冻结以后还能开通吗</td>\n",
       "      <td>我的条件可以开通花呗借款吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>如何得知关闭借呗</td>\n",
       "      <td>想永久关闭借呗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>花呗扫码付钱</td>\n",
       "      <td>二维码扫描可以用花呗吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no        sentence1                       sentence2  similarity\n",
       "0   1       怎么更改花呗手机号码  我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号           1\n",
       "1   2  也开不了花呗，就这样了？完事了                      真的嘛？就是花呗付款           0\n",
       "2   3      花呗冻结以后还能开通吗                   我的条件可以开通花呗借款吗           0\n",
       "3   4         如何得知关闭借呗                         想永久关闭借呗           0\n",
       "4   5           花呗扫码付钱                     二维码扫描可以用花呗吗           0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sim_data = pd.read_csv('./atec_nlp_sim_train_all.csv',sep='\\t')\n",
    "sim_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer, BertModel, AdamW, BertPreTrainedModel,get_linear_schedule_with_warmup,get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from typing import Tuple, List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "sentences = []\n",
    "features = 32\n",
    "for index,row in sim_data.iterrows():\n",
    "    sentences.append(row['sentence1'])\n",
    "    sentences.append(row['sentence2'])\n",
    "words = FastText(sentences,  size=features, window=3, min_count=1, iter=10,min_n = 3 , max_n = 6,word_ngrams = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda:0')\n",
    "train_df, val_df = train_test_split(sim_data, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\"\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "assert tokenizer.pad_token_id == 0, \"Padding value used in masks is set to zero, please change it everywhere\"\n",
    "train_df = pd.read_csv(os.path.join(path, 'atec_nlp_sim_train_all.csv'),sep='\\t')\n",
    "# training on a part of data for speed\n",
    "# train_df = train_df.sample(frac=0.33)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n",
      "D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "97353it [00:43, 2242.15it/s]\n",
      "5124it [00:02, 2063.20it/s]\n"
     ]
    }
   ],
   "source": [
    "class SimDataset(Dataset):\n",
    "    def __init__(self, dataframe, device):\n",
    "        self.device = device\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        for i, (row) in tqdm(dataframe.iterrows()):\n",
    "            text1 = sum([words[word] for word in row[\"sentence1\"]])/len(row)\n",
    "            text2 = sum([words[word] for word in row[\"sentence2\"]])/len(row)\n",
    "            val = [1-row[\"similarity\"]]\n",
    "#             print(val)\n",
    "            tags = torch.FloatTensor(val)\n",
    "            self.X.append([text1,text2])\n",
    "#             self.X.append(text1)\n",
    "\n",
    "            self.Y.append(tags)\n",
    "            self.X.append([text2,text1])\n",
    "            self.Y.append(tags)\n",
    "            if tags.shape[0]==0:\n",
    "                print(row[\"sentence1\"])\n",
    "                print(row[\"sentence2\"])\n",
    "                print(row[\"similarity\"])\n",
    "                print(tags)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[List[torch.FloatTensor], torch.LongTensor]:\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "def collate_fn(batch: List[Tuple[List[torch.FloatTensor], torch.LongTensor]]) \\\n",
    "        -> Tuple[torch.FloatTensor,torch.FloatTensor, torch.LongTensor]:\n",
    "    x, y = list(zip(*batch))\n",
    "#     print('-------------------')\n",
    "#     print(x)\n",
    "    x = list(zip(*x))\n",
    "    x1 = x[0]\n",
    "#     print(x1)\n",
    "#     print('-------------------')\n",
    "#     print(y)\n",
    "#     print('-------------------')\n",
    "#     print(*batch)\n",
    "    x2 = x[1]\n",
    "#     print(len(x1),type(x1))\n",
    "#     x1 = pad_sequence(x1, batch_first=True, padding_value=0)\n",
    "#     x2 = pad_sequence(x2, batch_first=True, padding_value=0)\n",
    "    y = torch.stack(y)\n",
    "    return x1, x2, y.to(device)\n",
    "\n",
    "train_dataset = SimDataset(train_df, device)\n",
    "dev_dataset = SimDataset(val_df, device)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "dev_sampler = RandomSampler(dev_dataset)\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "dev_iterator = DataLoader(dev_dataset, batch_size=BATCH_SIZE, sampler=dev_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97353it [01:32, 1049.48it/s]\n",
      "5124it [00:04, 1056.70it/s]\n"
     ]
    }
   ],
   "source": [
    "class SimDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, dataframe, device):\n",
    "        self.device = device\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_idx = tokenizer.pad_token_id\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        for i, (row) in tqdm(dataframe.iterrows()):\n",
    "            if len(tokenizer.tokenize(row[\"sentence1\"])) > 120:\n",
    "                continue\n",
    "            if len(tokenizer.tokenize(row[\"sentence2\"])) > 120:\n",
    "                continue\n",
    "            text1 = tokenizer.encode(row[\"sentence1\"], add_special_tokens=True)\n",
    "            text2 = tokenizer.encode(row[\"sentence2\"], add_special_tokens=True)\n",
    "\n",
    "            text1 = torch.LongTensor(text1)\n",
    "            text2 = torch.LongTensor(text2)\n",
    "            val = [1-row[\"similarity\"]]\n",
    "#             print(val)\n",
    "            tags = torch.FloatTensor(val)\n",
    "            self.X.append([text1,text2])\n",
    "#             self.X.append(text1)\n",
    "\n",
    "            self.Y.append(tags)\n",
    "            self.X.append([text2,text1])\n",
    "            self.Y.append(tags)\n",
    "            if tags.shape[0]==0:\n",
    "                print(row[\"sentence1\"])\n",
    "                print(row[\"sentence2\"])\n",
    "                print(row[\"similarity\"])\n",
    "                print(tags)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "def collate_fn(batch: List[Tuple[List[torch.LongTensor], torch.LongTensor]]) \\\n",
    "        -> Tuple[torch.LongTensor,torch.LongTensor, torch.LongTensor]:\n",
    "    x, y = list(zip(*batch))\n",
    "#     print('-------------------')\n",
    "#     print(x)\n",
    "    x = list(zip(*x))\n",
    "    x1 = x[0]\n",
    "#     print(x1)\n",
    "#     print('-------------------')\n",
    "#     print(y)\n",
    "#     print('-------------------')\n",
    "#     print(*batch)\n",
    "    x2 = x[1]\n",
    "#     print(len(x1),type(x1))\n",
    "    x1 = pad_sequence(x1, batch_first=True, padding_value=0)\n",
    "    x2 = pad_sequence(x2, batch_first=True, padding_value=0)\n",
    "    y = torch.stack(y)\n",
    "    return x1.to(device), x2.to(device), y.to(device)\n",
    "\n",
    "train_dataset = SimDataset(tokenizer, train_df, device)\n",
    "dev_dataset = SimDataset(tokenizer, val_df, device)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "dev_sampler = RandomSampler(dev_dataset)\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
    "dev_iterator = DataLoader(dev_dataset, batch_size=BATCH_SIZE, sampler=dev_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 2],) (3,)\n",
      "[(1, 3, 5), (2, 4, 6)]\n"
     ]
    }
   ],
   "source": [
    "t=[1,2],3\n",
    "test = [t]\n",
    "t,tt = list(zip(*test))\n",
    "print(t,tt)\n",
    "\n",
    "t = [1,2],[3,4],[5,6]\n",
    "print(list(zip(*t)))\n",
    "# class dismoid(torch.autograd.Function):\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def forward(ctx, input):\n",
    "#         ctx.save_for_backward(input)\n",
    "#         abs = torch.abs(input)\n",
    "#         return abs/(1+abs)\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output):\n",
    "#         input, = ctx.saved_tensors\n",
    "#         grad_input = grad_output.clone()\n",
    "#         abs = torch.abs(input)\n",
    "#         demon = 1+abs\n",
    "#         demon_2 = demon*demon\n",
    "#         grad_input[input >= 0] = 1/demon[input >= 0]-abs[input >= 0]/demon_2[input >= 0]\n",
    "#         grad_input[input < 0] = abs[input < 0]/demon_2[input < 0]-1/demon[input < 0]\n",
    "#         return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,features):\n",
    "        super(FastTextClassifier, self).__init__()\n",
    "        self.linear_left_1 = nn.Linear(features, 128)\n",
    "        self.relu_left = nn.ReLU()\n",
    "        self.linear_left_2 = nn.Linear(128, 64)\n",
    "\n",
    "        self.linear_right_1 = nn.Linear(features, 128)\n",
    "        self.relu_right = nn.ReLU()\n",
    "        self.linear_right_2 = nn.Linear(128, 64)\n",
    "        self.softsign = nn.Softsign()\n",
    "#         self.classifier = torch.Linear(128,2)\n",
    "        \n",
    "    def forward(self, input_ids1, input_ids2, token_type_ids=None, position_ids=None, head_mask=None,\n",
    "            labels=None):\n",
    "#         print(input_ids1)\n",
    "#         print('-----------')\n",
    "#         print(labels)\n",
    "        output1 = torch.FloatTensor(list(input_ids1))\n",
    "        output1 = self.linear_left_2(self.relu_left(self.linear_left_1(output1))) # batch, 2 \n",
    "#         output1 = torch.sigmoid(output1)\n",
    "        if input_ids2!=None:\n",
    "            output2 = torch.FloatTensor(list(input_ids2))\n",
    "            output2 = self.linear_right_2(self.relu_right(self.linear_right_1(output2))) # batch, 2\n",
    "#         output2 = torch.sigmoid(output2)\n",
    "\n",
    "            cls_output = self.softsign(F.pairwise_distance(output2,output1))\n",
    "            criterion = nn.BCELoss()\n",
    "            loss = 0\n",
    "            if labels is not None:\n",
    "                loss = criterion(cls_output, labels)\n",
    "            return loss, cls_output\n",
    "        else:\n",
    "            return output1\n",
    "\n",
    "model = FastTextClassifier(features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(BertPreTrainedModel):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BertClassifier, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.linear1 = nn.Linear(config.hidden_size, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.net1 = nn.Linear(128,64)\n",
    "        self.linear2 = nn.Linear(config.hidden_size, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.net2 = nn.Linear(128,64)\n",
    "        self.softsign = nn.Softsign()\n",
    "#         self.classifier = torch.Linear(128,2)\n",
    "        \n",
    "    def forward(self, input_ids1, input_ids2=None, attention_mask1=None, attention_mask2=None, token_type_ids=None, position_ids=None, head_mask=None,\n",
    "                \n",
    "            labels=None):\n",
    "        outputs1 = self.bert(input_ids1,\n",
    "                               attention_mask=attention_mask1,\n",
    "                               token_type_ids=token_type_ids,\n",
    "                               position_ids=position_ids,\n",
    "                               head_mask=head_mask)\n",
    "        output1 = self.net1(self.relu1(self.linear1(outputs1[1]))) # batch, 2 \n",
    "        if input_ids2 is not None:\n",
    "            outputs2 = self.bert(input_ids2,\n",
    "                       attention_mask=attention_mask2,\n",
    "                       token_type_ids=token_type_ids,\n",
    "                       position_ids=position_ids,\n",
    "                       head_mask=head_mask)\n",
    "            output2 = self.net2(self.relu2(self.linear2(outputs2[1]))) # batch, 2\n",
    "            cls_output = self.softsign(F.pairwise_distance(output2,output1))\n",
    "            criterion = nn.BCELoss()\n",
    "            loss = 0\n",
    "            if labels is not None:\n",
    "                loss = criterion(cls_output, labels)\n",
    "            return loss, cls_output\n",
    "        else:\n",
    "            return output1\n",
    "        \n",
    "    def save(self,filename):\n",
    "        torch.save(self.state_dict(),filename)\n",
    "        # torch.save(self.net2, filename)\n",
    "        \n",
    "    def load(self,filename):\n",
    "        self.load_state_dict(torch.load(PATH))\n",
    "        self.eval()\n",
    "        # self.net1 = torch.load(filename)\n",
    "\n",
    "model = BertClassifier.from_pretrained('bert-base-chinese').to(device)\n",
    "# model = BertClassifier.from_pretrained('bert-base-cased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "#     print(type(iterator))\n",
    "    for x1,x2,y in tqdm(iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, outputs = model(x1, x2, labels=y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_loss = total_loss / len(iterator)\n",
    "    print(f\"Train loss {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    true = []\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for x1,x2, y in tqdm(iterator):\n",
    "            loss, outputs = model(x1,x2, labels=y)\n",
    "            total_loss += loss\n",
    "            true += y.cpu().numpy().tolist()\n",
    "            pred += outputs.cpu().numpy().tolist()\n",
    "    true = np.array(true)\n",
    "    pred = np.array(pred)\n",
    "#     print(true.reshape(1,-1))\n",
    "#     print('-----------')\n",
    "#     print(pred)\n",
    "    for i, name in enumerate(['similarity']):\n",
    "        val = roc_auc_score(true.reshape(1,-1)[0], pred)\n",
    "        print(f\"{name} roc_auc {val}\")\n",
    "    avg_loss = total_loss / len(iterator)\n",
    "    print(f\"Evaluate loss {avg_loss}\")\n",
    "    return avg_loss,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "#     print(type(iterator))\n",
    "    for x1,x2,y in tqdm(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        mask1 = (x1 != 0).float()\n",
    "        mask2 = (x2 != 0).float()\n",
    "\n",
    "#         print(x1)\n",
    "#         print('+++++++++++++++++++++++++++++++++++')\n",
    "#         print(x2)\n",
    "        try:\n",
    "            loss, outputs = model(x1, x2, attention_mask1=mask1,attention_mask2 = mask2, labels=y)\n",
    "        except:\n",
    "            print(x1)\n",
    "            print('++++++++++')\n",
    "            print(x2)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_loss = total_loss / len(iterator)\n",
    "    print(f\"Train loss {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    true = []\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for x1,x2, y in tqdm(iterator):\n",
    "            mask1 = (x1 != 0).float()\n",
    "            mask2 = (x2 != 0).float()\n",
    "            loss, outputs = model(x1, x2, attention_mask1=mask1,attention_mask2 = mask2, labels=y)\n",
    "            total_loss += loss\n",
    "            true += y.cpu().numpy().tolist()\n",
    "            pred += outputs.cpu().numpy().tolist()\n",
    "    true = np.array(true)\n",
    "    pred = np.array(pred)\n",
    "    for i, name in enumerate(['similarity']):\n",
    "        val = roc_auc_score(true.reshape(1,-1)[0], pred)\n",
    "        print(f\"{name} roc_auc {val}\")\n",
    "    avg_loss = total_loss / len(iterator)\n",
    "    print(f\"Evaluate loss {avg_loss}\")\n",
    "    return avg_loss,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "{'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "{'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_NUM = 50\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "rocs = []\n",
    "start_epoch = -1\n",
    "\n",
    "checkpoint_name='checkpoint.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载模式再训练\n",
    "checkpoint = torch.load(checkpoint_name)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "start_epoch = checkpoint['epoch']\n",
    "losses = checkpoint['train_loss']\n",
    "val_losses = checkpoint['val_loss']\n",
    "rocs = checkpoint['auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: -1\n",
      "0\n",
      "1204781 12169\n"
     ]
    }
   ],
   "source": [
    "print(f\"current epoch: {start_epoch}\")\n",
    "print(len(losses))\n",
    "# triangular learning rate, linearly grows untill half of first epoch, then linearly decays \n",
    "warmup_steps = int(0.5 * len(train_iterator))\n",
    "total_steps = len(train_iterator) * EPOCH_NUM - warmup_steps\n",
    "print(total_steps,warmup_steps)\n",
    "scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps,last_epoch=start_epoch)\n",
    "# scheduler = get_linear_schedule_with_warmuparmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps,last_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存以便下次训练\n",
    "try:\n",
    "    if start_epoch is None: start_epoch = 0\n",
    "except NameError:\n",
    "    start_epoch = 0\n",
    "    \n",
    "def save_checkpoint(model,optimizer,start_epoch,filename):\n",
    "    all_state = {'model':model.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch': start_epoch,'train_loss':losses,'val_loss':val_losses,'auc':rocs}\n",
    "\n",
    "    torch.save(all_state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== EPOCH 0 ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/24339 [00:00<?, ?it/s]D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "100%|█████████████████████████████████████████████████████████████████████████▉| 24338/24339 [1:55:09<00:00,  3.37it/s]D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 24339/24339 [1:55:09<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.46492970097621616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1281/1281 [01:23<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity roc_auc 0.5281497306517973\n",
      "Evaluate loss 0.4749499559402466\n",
      "================================================== EPOCH 1 ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/24339 [00:00<?, ?it/s]D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "100%|█████████████████████████████████████████████████████████████████████████▉| 24338/24339 [2:03:00<00:00,  3.29it/s]D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 24339/24339 [2:03:01<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.47555014945817975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1281/1281 [01:25<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity roc_auc 0.5256215092260309\n",
      "Evaluate loss 0.4739690124988556\n",
      "================================================== EPOCH 2 ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/24339 [00:00<?, ?it/s]D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "100%|█████████████████████████████████████████████████████████████████████████▉| 24338/24339 [2:01:33<00:00,  3.62it/s]D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 24339/24339 [2:01:33<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.47543053993081064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1281/1281 [01:22<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity roc_auc 0.517288929454569\n",
      "Evaluate loss 0.47402822971343994\n",
      "================================================== EPOCH 3 ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/24339 [00:00<?, ?it/s]D:\\UnixlikePrograms\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      " 64%|███████████████████████████████████████████████▎                          | 15561/24339 [1:16:50<45:11,  3.24it/s]"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCH_NUM-start_epoch-1):\n",
    "    print('=' * 50, f\"EPOCH {start_epoch+i+1}\", '=' * 50)\n",
    "    l = train(model, train_iterator, optimizer, scheduler)\n",
    "    losses.append(l)\n",
    "    l,r = evaluate(model, dev_iterator)\n",
    "    val_losses.append(l)\n",
    "    rocs.append(r)\n",
    "    save_checkpoint(model,optimizer,i,checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model,optimizer,start_epoch+i,'checkpoint.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17bab885dd8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(len(losses))\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "\n",
    "plt.sca(ax1)\n",
    "plt.plot(x, losses, 'r',label='train loss')\n",
    "plt.plot(x, val_losses, ms=10,label='validate loss')\n",
    "plt.legend()  # 让图例生效\n",
    "\n",
    "plt.sca(ax2)\n",
    "plt.plot(x, rocs, 'g',ms=10,label='auc')\n",
    "\n",
    "plt.legend()  # 让图例生效\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.1027, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2360, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2215, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1934, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1940, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.9548, grad_fn=<BinaryCrossEntropyBackward>), tensor(1.1011, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1890, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1255, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1997, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1775, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2117, grad_fn=<BinaryCrossEntropyBackward>), tensor(1.5485, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1266, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.6800, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1041, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.8624, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.0915, grad_fn=<BinaryCrossEntropyBackward>), tensor(1.6718, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.7334, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2202, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1904, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1561, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1740, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1440, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1524, grad_fn=<BinaryCrossEntropyBackward>), tensor(1.9979, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.6241, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2134, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.5964, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1839, grad_fn=<BinaryCrossEntropyBackward>), tensor(1.0047, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1282, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.8252, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.8369, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.3340, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.8254, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1780, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1540, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1822, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.1619, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2137, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.9330, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2375, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2246, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2512, grad_fn=<BinaryCrossEntropyBackward>), tensor(0.2208, grad_fn=<BinaryCrossEntropyBackward>)]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
